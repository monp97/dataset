{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gender_prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/monp97/dataset/blob/master/gender_prediction_backup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqtf8NArxSiH",
        "colab_type": "code",
        "outputId": "fd5b354d-1487-4734-dccc-da9ba0b6af42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "! git clone https://github.com/monp97/dataset.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'dataset'...\n",
            "remote: Enumerating objects: 62939, done.\u001b[K\n",
            "remote: Total 62939 (delta 0), reused 0 (delta 0), pack-reused 62939\u001b[K\n",
            "Receiving objects: 100% (62939/62939), 426.50 MiB | 32.46 MiB/s, done.\n",
            "Resolving deltas: 100% (2988/2988), done.\n",
            "Checking out files: 100% (119386/119386), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7GgQ3rVaIaw",
        "colab_type": "code",
        "outputId": "9a9d76a8-bfea-44b3-d6a0-0e8f55399372",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "\n",
        "directory = \"final_dataset\"\n",
        "  \n",
        "# Parent Directory path \n",
        "parent_dir = \"/content/\"\n",
        "  \n",
        "# Path \n",
        "path = os.path.join(parent_dir, directory) \n",
        "  \n",
        "# Create the directory \n",
        "# 'GeeksForGeeks' in \n",
        "# '/home / User / Documents' \n",
        "os.mkdir(path) \n",
        "print(\"Directory '% s' created\" % directory) \n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Directory 'final_dataset' created\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YphEzVsadV0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "directory1 = \"training\"\n",
        "directory2 = \"test\"\n",
        "\n",
        "# Parent Directory path \n",
        "parent_dir = \"/content/final_dataset\"\n",
        "  \n",
        "# Path \n",
        "path1 = os.path.join(parent_dir, directory1) \n",
        "path2 = os.path.join(parent_dir, directory2) \n",
        "  \n",
        "# Create the directory \n",
        "# 'GeeksForGeeks' in \n",
        "# '/home / User / Documents' \n",
        "os.mkdir(path1) \n",
        "os.mkdir(path2) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaeFWesrbhLl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "directories = [\"female_left\",\"male_left\",\"female_right\",\"male_right\"]\n",
        "  \n",
        "# Parent Directory path \n",
        "parent_dir = \"/content/final_dataset/training\"\n",
        "\n",
        "list_final_dir=[]\n",
        "\n",
        "for dir in directories:\n",
        "  for i in range(5):\n",
        "    list_final_dir.append(dir+'_'+str(i+1))\n",
        "  \n",
        "# Path \n",
        "# path1 = os.path.join(parent_dir, directory1) \n",
        "# path2 = os.path.join(parent_dir, directory2) \n",
        "\n",
        "for i in range(len(list_final_dir)):\n",
        "  path = os.path.join(parent_dir, list_final_dir[i]) \n",
        "  os.mkdir(path) \n",
        "   \n",
        "# # Create the directory \n",
        "# # 'GeeksForGeeks' in \n",
        "# # '/home / User / Documents' \n",
        "# os.mkdir(path1) \n",
        "# os.mkdir(path2) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYyz43agRV6G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "directories = [\"female_left\",\"male_left\",\"female_right\",\"male_right\"]\n",
        "\n",
        "  \n",
        "# Parent Directory path \n",
        "parent_dir = \"/content/final_dataset/test\"\n",
        "\n",
        "list_final_dir=[]\n",
        "\n",
        "for dir in directories:\n",
        "  for i in range(5):\n",
        "    list_final_dir.append(dir+'_'+str(i+1))\n",
        "  \n",
        "# Path \n",
        "# path1 = os.path.join(parent_dir, directory1) \n",
        "# path2 = os.path.join(parent_dir, directory2) \n",
        "\n",
        "for i in range(len(list_final_dir)):\n",
        "  path = os.path.join(parent_dir, list_final_dir[i]) \n",
        "  os.mkdir(path) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TT6BuBm1Q8R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "dst = 'path/to/dest_dir'\n",
        "\n",
        "images = []\n",
        "i=0\n",
        "f=0\n",
        "m=0\n",
        "for filename in os.listdir('/content/dataset/Real'):\n",
        "        subject_id, etc = filename.split('__')\n",
        "        gender, lr, finger, _ = etc.split('_')\n",
        "        src='/content/dataset/Real/'+filename\n",
        "        i=i+1\n",
        "\n",
        "        refer = {\n",
        "          \"index\": \"1\",\n",
        "          \"middle\": \"2\",\n",
        "          \"ring\":\"3\",\n",
        "          \"little\":\"4\",\n",
        "          \"thumb\":\"5\"\n",
        "        }\n",
        "\n",
        "        dir_name=''\n",
        "\n",
        "        if gender=='M':\n",
        "          dir_name=dir_name+'male_'\n",
        "        else:\n",
        "          dir_name=dir_name+'female_'\n",
        "\n",
        "        if lr=='Left':\n",
        "          dir_name=dir_name+'left_'\n",
        "        else:\n",
        "          dir_name=dir_name+'right_'\n",
        "\n",
        "        dir_name=dir_name+refer[finger]\n",
        "\n",
        "        shutil.copy(src,'/content/final_dataset/training/'+dir_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRtma-VHkVNT",
        "colab_type": "code",
        "outputId": "cb843960-1e34-4533-d4d7-e72feeb41e2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(i)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y26Sau2DkWJN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil\n",
        "import os\n",
        "import numpy as np\n",
        "import argparse\n",
        "\n",
        "def get_files_from_folder(path):\n",
        "\n",
        "    files = os.listdir(path)\n",
        "    return np.asarray(files)\n",
        "\n",
        "def main(path_to_data, path_to_test_data, train_ratio):\n",
        "    # get dirs\n",
        "    _, dirs, _ = next(os.walk(path_to_data))\n",
        "\n",
        "    # calculates how many train data per class\n",
        "    data_counter_per_class = np.zeros((len(dirs)))\n",
        "    for i in range(len(dirs)):\n",
        "        path = os.path.join(path_to_data, dirs[i])\n",
        "        files = get_files_from_folder(path)\n",
        "        data_counter_per_class[i] = len(files)\n",
        "    test_counter = np.round(data_counter_per_class * (1 - train_ratio))\n",
        "\n",
        "    # transfers files\n",
        "    for i in range(len(dirs)):\n",
        "        path_to_original = os.path.join(path_to_data, dirs[i])\n",
        "        path_to_save = os.path.join(path_to_test_data, dirs[i])\n",
        "\n",
        "        #creates dir\n",
        "        if not os.path.exists(path_to_save):\n",
        "            os.makedirs(path_to_save)\n",
        "        files = get_files_from_folder(path_to_original)\n",
        "        # moves data\n",
        "        for j in range(int(test_counter[i])):\n",
        "            dst = os.path.join(path_to_save, files[j])\n",
        "            src = os.path.join(path_to_original, files[j])\n",
        "            shutil.move(src, dst)\n",
        "\n",
        "    \n",
        "# def parse_args():\n",
        "#   parser = argparse.ArgumentParser(description=\"Dataset divider\")\n",
        "#   parser.add_argument(\"--data_path\", required=True,\n",
        "#     help=\"Path to data\")\n",
        "#   parser.add_argument(\"--test_data_path_to_save\", required=True,\n",
        "#     help=\"Path to test data where to save\")\n",
        "#   parser.add_argument(\"--train_ratio\", required=True,\n",
        "#     help=\"Train ratio - 0.7 means splitting data in 70 % train and 30 % test\")\n",
        "#   return parser.parse_args()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  # args = parse_args()\n",
        "  # args.data_path='/content/final_dataset/training'\n",
        "  # args.test_data_path_to_save='/content/final_dataset/test'\n",
        "  # args.train_ratio=0.8\n",
        "  main('/content/final_dataset/training','/content/final_dataset/test', float(0.8))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uNq6-FqY52p",
        "colab_type": "code",
        "outputId": "86cab947-738f-43d8-8f3c-325d2f0e132f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "source1 = \"/content/final_dataset/training\"\n",
        "dest11 = \"/content/final_dataset/test\"\n",
        "\n",
        "files1 = os.listdir(source1)\n",
        "files2 = os.listdir(dest11)\n",
        "\n",
        "\n",
        "for file in files1:\n",
        "  files_file= os.listdir(\"/content/final_dataset/training/\"+file)\n",
        "  print(\"training data \"+str(file)+' '+str(len(files_file)))\n",
        "\n",
        "\n",
        "for file in files2:\n",
        "  files_file= os.listdir(\"/content/final_dataset/test/\"+file)\n",
        "  print(\"test data \"+str(file)+' '+str(len(files_file)))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training data female_left_3 98\n",
            "training data female_left_5 98\n",
            "training data female_left_2 98\n",
            "training data female_right_2 98\n",
            "training data female_right_5 98\n",
            "training data female_right_3 98\n",
            "training data male_left_4 382\n",
            "training data female_left_4 98\n",
            "training data male_left_5 382\n",
            "training data male_left_2 382\n",
            "training data female_right_4 98\n",
            "training data male_right_2 382\n",
            "training data male_right_5 382\n",
            "training data female_right_1 98\n",
            "training data male_right_3 382\n",
            "training data male_right_4 382\n",
            "training data male_left_1 382\n",
            "training data male_right_1 382\n",
            "training data male_left_3 382\n",
            "training data female_left_1 98\n",
            "test data female_left_3 25\n",
            "test data female_left_5 25\n",
            "test data female_left_2 25\n",
            "test data female_right_2 25\n",
            "test data female_right_5 25\n",
            "test data female_right_3 25\n",
            "test data male_left_4 95\n",
            "test data female_left_4 25\n",
            "test data male_left_5 95\n",
            "test data male_left_2 95\n",
            "test data female_right_4 25\n",
            "test data male_right_2 95\n",
            "test data male_right_5 95\n",
            "test data female_right_1 25\n",
            "test data male_right_3 95\n",
            "test data male_right_4 95\n",
            "test data male_left_1 95\n",
            "test data male_right_1 95\n",
            "test data male_left_3 95\n",
            "test data female_left_1 25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjPAXdP4CArE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#image augmentation code functions\n",
        "\n",
        "import random\n",
        "from scipy import ndarray\n",
        "import skimage as sk\n",
        "from skimage import transform\n",
        "from skimage import util\n",
        "\n",
        "def random_rotation(image_array: ndarray):\n",
        "    # pick a random degree of rotation between 25% on the left and 25% on the right\n",
        "    random_degree = random.uniform(-25, 25)\n",
        "    return sk.transform.rotate(image_array, random_degree)\n",
        "\n",
        "def random_noise(image_array: ndarray):\n",
        "    # add random noise to the image\n",
        "    return sk.util.random_noise(image_array)\n",
        "\n",
        "def horizontal_flip(image_array: ndarray):\n",
        "    # horizontal flip doesn't need skimage, it's easy as flipping the image array of pixels !\n",
        "    return image_array[:, ::-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PX6_5QSwGwGt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import os\n",
        "import skimage\n",
        "from skimage import data, io, filters\n",
        "\n",
        "# our folder path containing some images\n",
        "\n",
        "def augmentFolderContent(folder_name,num_files_desired):\n",
        "  folder_path = '/content/final_dataset/training/'+folder_name\n",
        "  # the number of file to generate\n",
        "\n",
        "  # loop on all files of the folder and build a list of files paths\n",
        "  images = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
        "\n",
        "  num_generated_files = 0\n",
        "  while num_generated_files <= num_files_desired:\n",
        "      # random image from the folder\n",
        "      image_path = random.choice(images)\n",
        "      # read image as an two dimensional array of pixels\n",
        "      image_to_transform = sk.io.imread(image_path)\n",
        "      num_generated_files+=1\n",
        "      available_transformations = {\n",
        "      'rotate': random_rotation,\n",
        "      'noise': random_noise,\n",
        "      'horizontal_flip': horizontal_flip\n",
        "      }\n",
        "\n",
        "      # random num of transformations to apply\n",
        "      num_transformations_to_apply = random.randint(1, len(available_transformations))\n",
        "\n",
        "      num_transformations = 0\n",
        "      transformed_image = None\n",
        "      while num_transformations <= num_transformations_to_apply:\n",
        "          # choose a random transformation to apply for a single image\n",
        "          key = random.choice(list(available_transformations))\n",
        "          transformed_image = available_transformations[key](image_to_transform)\n",
        "          num_transformations += 1\n",
        "\n",
        "\n",
        "      transformed_image=skimage.img_as_ubyte(transformed_image)\n",
        "\n",
        "      new_file_path = '%s/augmented_image_%s.BMP' % (folder_path, num_generated_files)\n",
        "\n",
        "      # write image to the disk\n",
        "      sk.io.imsave(new_file_path, transformed_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUjO5tr7MQdB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "source1 = \"/content/final_dataset/training\"\n",
        "\n",
        "\n",
        "folder = os.listdir(source1)\n",
        "\n",
        "\n",
        "for file in folder:\n",
        "  folder_under= os.listdir(\"/content/final_dataset/training/\"+file)\n",
        "  files_desired=1000-len(folder_under)\n",
        "  augmentFolderContent(file,files_desired)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjHC_fS9Aw6R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y16IA6BRmzVr",
        "colab_type": "code",
        "outputId": "c99d7b5f-01ff-4049-8f57-b750bbc608c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "source1 = \"/content/final_dataset/training/male\"\n",
        "dest11 = \"/content/final_dataset/training/female\"\n",
        "files1 = os.listdir(source1)\n",
        "files2 = os.listdir(dest11)\n",
        "print(len(files1))\n",
        "print(len(files2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3816\n",
            "984\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObxKwoypPSfc",
        "colab_type": "code",
        "outputId": "c0a0958a-aa0f-4ed7-908a-697cf04370c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "source1 = \"/content/final_dataset/training\"\n",
        "dest11 = \"/content/final_dataset/test\"\n",
        "\n",
        "files1 = os.listdir(source1)\n",
        "files2 = os.listdir(dest11)\n",
        "\n",
        "\n",
        "for file in files1:\n",
        "  files_file= os.listdir(\"/content/final_dataset/training/\"+file)\n",
        "  print(\"training data \"+str(file)+' '+str(len(files_file)))\n",
        "\n",
        "\n",
        "for file in files2:\n",
        "  files_file= os.listdir(\"/content/final_dataset/test/\"+file)\n",
        "  print(\"test data \"+str(file)+' '+str(len(files_file)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training data female_left_3 1001\n",
            "training data female_left_5 1001\n",
            "training data female_left_2 1001\n",
            "training data female_right_2 1001\n",
            "training data female_right_5 1001\n",
            "training data female_right_3 1001\n",
            "training data male_left_4 1001\n",
            "training data female_left_4 1001\n",
            "training data male_left_5 1001\n",
            "training data male_left_2 1001\n",
            "training data female_right_4 1001\n",
            "training data male_right_2 1001\n",
            "training data male_right_5 1001\n",
            "training data female_right_1 1001\n",
            "training data male_right_3 1001\n",
            "training data male_right_4 1001\n",
            "training data male_left_1 1001\n",
            "training data male_right_1 1001\n",
            "training data male_left_3 1001\n",
            "training data female_left_1 1001\n",
            "test data female_left_3 25\n",
            "test data female_left_5 25\n",
            "test data female_left_2 25\n",
            "test data female_right_2 25\n",
            "test data female_right_5 25\n",
            "test data female_right_3 25\n",
            "test data male_left_4 95\n",
            "test data female_left_4 25\n",
            "test data male_left_5 95\n",
            "test data male_left_2 95\n",
            "test data female_right_4 25\n",
            "test data male_right_2 95\n",
            "test data male_right_5 95\n",
            "test data female_right_1 25\n",
            "test data male_right_3 95\n",
            "test data male_right_4 95\n",
            "test data male_left_1 95\n",
            "test data male_right_1 95\n",
            "test data male_left_3 95\n",
            "test data female_left_1 25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxfV5OIwaKG8",
        "colab_type": "code",
        "outputId": "d72746d0-2e2c-4ade-9b8a-0a59f1cab79d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen=ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "test_datagen=ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "training_set=train_datagen.flow_from_directory(\n",
        "    '/content/final_dataset/training',\n",
        "    target_size=(64,64),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "test_set=test_datagen.flow_from_directory(\n",
        "    '/content/final_dataset/test',\n",
        "    target_size=(64,64),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 20020 images belonging to 20 classes.\n",
            "Found 1200 images belonging to 20 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZ2mnQiiRmWC",
        "colab_type": "code",
        "outputId": "779f62f1-55fb-4ef0-e0e8-453d9c1dcdc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "x,y = training_set.next()\n",
        "print(x[0].shape)\n",
        "print(y[0].shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 64, 3)\n",
            "(20,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ecnxx1u2bFc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras import optimizers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dmf8ryd5ZGOW",
        "colab_type": "code",
        "outputId": "4ad8c398-dc74-48ae-8d09-878674e2f5f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "classifier=Sequential()\n",
        "classifier.add(Convolution2D(64,3,3,input_shape=(64,64,3),activation='relu'))\n",
        "classifier.add(MaxPooling2D(pool_size=(3,3)))\n",
        "\n",
        "classifier.add(Convolution2D(128,3,3,activation='relu'))\n",
        "classifier.add(MaxPooling2D(pool_size=(3,3)))\n",
        "classifier.add(Flatten())\n",
        "print(classifier.summary())\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_25 (Conv2D)           (None, 62, 62, 64)        1792      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_18 (MaxPooling (None, 20, 20, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 18, 18, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_19 (MaxPooling (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_11 (Flatten)         (None, 4608)              0         \n",
            "=================================================================\n",
            "Total params: 75,648\n",
            "Trainable params: 75,648\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), input_shape=(64, 64, 3..., activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\")`\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmbNON6VSxyq",
        "colab_type": "code",
        "outputId": "3fe557a1-4137-4e02-e349-6869649c91c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "classifier.summary"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Network.summary of <keras.engine.sequential.Sequential object at 0x7fc1f21986a0>>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBROn29oZpCJ",
        "colab_type": "code",
        "outputId": "3993b607-0052-4d8a-807f-b5810557c039",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "classifier.add(Dense(output_dim=128, activation='relu'))\n",
        "classifier.add(Dense(output_dim=20,activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=20)`\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEPYOR10Z194",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = optimizers.adam(lr=0.0008)\n",
        "classifier.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQVuCrGmjb3a",
        "colab_type": "code",
        "outputId": "28812ccb-d93d-46b7-81f3-525910aed393",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "! pip install -U imbalanced-learn"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting imbalanced-learn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/73/36a13185c2acff44d601dc6107b5347e075561a49e15ddd4e69988414c3e/imbalanced_learn-0.6.2-py3-none-any.whl (163kB)\n",
            "\r\u001b[K     |██                              | 10kB 26.4MB/s eta 0:00:01\r\u001b[K     |████                            | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 30kB 2.4MB/s eta 0:00:01\r\u001b[K     |████████                        | 40kB 1.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |████████████                    | 61kB 2.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 71kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████                | 81kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 92kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 102kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 112kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 122kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 133kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 143kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 153kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 163kB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scikit-learn>=0.22 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (0.22.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.17.5)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.17 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (0.14.1)\n",
            "Installing collected packages: imbalanced-learn\n",
            "  Found existing installation: imbalanced-learn 0.4.3\n",
            "    Uninstalling imbalanced-learn-0.4.3:\n",
            "      Successfully uninstalled imbalanced-learn-0.4.3\n",
            "Successfully installed imbalanced-learn-0.6.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrKpWbnAwEUt",
        "colab_type": "code",
        "outputId": "f33ab6aa-b638-486d-eb8b-b64036299ede",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "from IPython.display import display\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "classifier.fit_generator(training_set,\n",
        "                    steps_per_epoch=3200,\n",
        "                    epochs=10,\n",
        "                    validation_data=test_set,\n",
        "                    nb_val_samples=800)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., steps_per_epoch=3200, epochs=10, validation_data=<keras_pre..., validation_steps=800)`\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "3200/3200 [==============================] - 142s 44ms/step - loss: 2.2378 - acc: 0.2623 - val_loss: 2.1399 - val_acc: 0.3038\n",
            "Epoch 2/10\n",
            " 442/3200 [===>..........................] - ETA: 1:49 - loss: 1.9815 - acc: 0.3415"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tN6DUQi8W7cO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmdDuzKef3pm",
        "colab_type": "code",
        "outputId": "2dcf2401-d998-45c9-f066-cb57e9785621",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "source1 = \"/content/final_dataset/test/female\"\n",
        "dest11 = \"/content/final_dataset/test/male\"\n",
        "files = os.listdir(source1)\n",
        "len(files)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-320425257493>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msource1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/final_dataset/female\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdest11\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/final_dataset/male\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/final_dataset/female'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbu3M0CXe-ri",
        "colab_type": "code",
        "outputId": "2a57b4ff-af08-489f-8f76-8ab893d74522",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "files = os.listdir(source1)\n",
        "len(files)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "948"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pB_XslX-fNQR",
        "colab_type": "code",
        "outputId": "209ba5ce-314d-479c-d340-1883c66e1476",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "dest11 = \"/content/final_dataset/test/female\"\n",
        "files = os.listdir(dest11)\n",
        "print(len(files))\n",
        "dest12 = \"/content/final_dataset/test/male\"\n",
        "files = os.listdir(dest12)\n",
        "print(len(files))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "246\n",
            "955\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-J7VWe8Tgs3x",
        "colab_type": "code",
        "outputId": "6cb54ca2-3b24-4857-c08a-dc1588642644",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "source1 = \"/content/final_dataset/training/female\"\n",
        "dest11 = \"/content/final_dataset/test/female\"\n",
        "files = os.listdir(source1)\n",
        "len(files)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "984"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qy-pY2YthEWn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil\n",
        "shutil.rmtree('/content/final_dataset')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tj6-xI4s0H2",
        "colab_type": "code",
        "outputId": "8b2471b5-0b10-4c99-8d8d-e635489e4b8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "_, train_acc = classifier.evaluate(training_set , verbose=0)\n",
        "_, test_acc = classifier.evaluate(test_set, verbose=0)\n",
        "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
        "# plot loss during training"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train: 0.941, Test: 0.773\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kz2K9xrRTm2p",
        "colab_type": "code",
        "outputId": "d91708b7-b3c8-4cb9-ce7c-b0b48b631a02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "pred=classifier.predict_generator(test_set)\n",
        "pred = np.argmax(pred, axis=-1) #multiple categories\n",
        "\n",
        "actual=test_set.classes\n",
        "\n",
        "label_map = (training_set.class_indices)\n",
        "\n",
        "label_map = dict((v,k) for k,v in label_map.items()) #flip k,v\n",
        "\n",
        "predictions = [label_map[k] for k in pred]\n",
        "\n",
        "actual1 = [\"\" for x in range(1200)]\n",
        "\n",
        "\n",
        "for i in range(1200):\n",
        "  if actual[i]==0:\n",
        "    actual1[i]='female'\n",
        "  else:\n",
        "    actual1[i]='male'\n",
        "\n",
        "\n",
        "print(predictions)\n",
        "print(actual1)\n",
        "k=0;\n",
        "\n",
        "count=0\n",
        "\n",
        "for i in range(1200):\n",
        "  if predictions[i]==actual1[i]:\n",
        "    count=count+1\n",
        "\n",
        "\n",
        "print(count)\n",
        "\n",
        "# for i in predictions:\n",
        "#   if i=='male':\n",
        "#     k=k+1;\n",
        "\n",
        "# print(k)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['male', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'female', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'female', 'male', 'female', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'female', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'female', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'female', 'female', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'female', 'male', 'male', 'female', 'male', 'female', 'male', 'male', 'female', 'female', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'female', 'female', 'female', 'male', 'female', 'male', 'male', 'male', 'female', 'male', 'female', 'male', 'female', 'male', 'female', 'female', 'male', 'female', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'female', 'male', 'male', 'male', 'female', 'male', 'female', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'female', 'female', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'female', 'female', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'female', 'male', 'male', 'female', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'female', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'female', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'female', 'female', 'female', 'female', 'female', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'female', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'female', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'female', 'male', 'male', 'female', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'female', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'female', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'female', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'female', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male']\n",
            "['female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male']\n",
            "928\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-9A1nU9XcAo",
        "colab_type": "code",
        "outputId": "6127e3fe-5769-4357-b374-bed56aa4d95e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cor=0;\n",
        "for i in range(954):\n",
        "  if predictions[246+i]=='female':\n",
        "    cor=cor+1;\n",
        "\n",
        "print(cor)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "84\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}