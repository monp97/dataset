{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPuRKppSOVc8fWekb4g+54T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/monp97/dataset/blob/master/Hand_classification_85.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mG5L22iwQqjV",
        "colab_type": "code",
        "outputId": "f728fc15-6b7a-417f-d70e-9d220f086b0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "! git clone https://github.com/monp97/dataset.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'dataset'...\n",
            "remote: Enumerating objects: 7688, done.\u001b[K\n",
            "remote: Counting objects: 100% (7688/7688), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7428/7428), done.\u001b[K\n",
            "remote: Total 70627 (delta 265), reused 7677 (delta 260), pack-reused 62939\n",
            "Receiving objects: 100% (70627/70627), 454.05 MiB | 29.93 MiB/s, done.\n",
            "Resolving deltas: 100% (3253/3253), done.\n",
            "Checking out files: 100% (128229/128229), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0TnRHUDZFe1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil\n",
        "shutil.rmtree('/content/final_gender_dataset')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_5wbeAzWwWN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "f385677c-aea3-40fe-e891-d402434218dd"
      },
      "source": [
        "! pip install split-folders"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting split-folders\n",
            "  Downloading https://files.pythonhosted.org/packages/20/67/29dda743e6d23ac1ea3d16704d8bbb48d65faf3f1b1eaf53153b3da56c56/split_folders-0.3.1-py3-none-any.whl\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5K4MVSvsWy1J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c67ae120-d87e-4440-e460-f5c6b448b50e"
      },
      "source": [
        "import split_folders\n",
        "\n",
        "# Split with a ratio.\n",
        "# To only split into training and validation set, set a tuple to `ratio`, i.e, `(.8, .2)`.\n",
        "split_folders.ratio('/content/final_gender_dataset/training', output=\"output\", seed=1337, ratio=(.8, .1, .1)) # default values"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying files: 6000 files [00:00, 6212.85 files/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5NSU5tbXHwS",
        "colab_type": "code",
        "outputId": "3344007f-5903-495a-9dd4-cbbbf94df980",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "\n",
        "directory = \"final_gender_dataset\"\n",
        "  \n",
        "# Parent Directory path \n",
        "parent_dir = \"/content/\"\n",
        "  \n",
        "# Path \n",
        "path = os.path.join(parent_dir, directory) \n",
        "  \n",
        "# Create the directory \n",
        "# 'GeeksForGeeks' in \n",
        "# '/home / User / Documents' \n",
        "os.mkdir(path) \n",
        "print(\"Directory '% s' created\" % directory) "
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Directory 'final_gender_dataset' created\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNUKOQwlXK1m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "directory1 = \"training\"\n",
        "directory2 = \"test\"\n",
        "\n",
        "# Parent Directory path \n",
        "parent_dir = \"/content/final_gender_dataset\"\n",
        "  \n",
        "# Path \n",
        "path1 = os.path.join(parent_dir, directory1) \n",
        "path2 = os.path.join(parent_dir, directory2) \n",
        "  \n",
        "# Create the directory \n",
        "# 'GeeksForGeeks' in \n",
        "# '/home / User / Documents' \n",
        "os.mkdir(path1) \n",
        "os.mkdir(path2) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6PbTxyLXR_c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "directory1 = \"left\"\n",
        "directory2 = \"right\"\n",
        "\n",
        "# Parent Directory path \n",
        "parent_dir = \"/content/final_gender_dataset/training\"\n",
        "  \n",
        "# Path \n",
        "path1 = os.path.join(parent_dir,directory1) \n",
        "path2 = os.path.join(parent_dir, directory2) \n",
        "  \n",
        "# Create the directory \n",
        "# 'GeeksForGeeks' in \n",
        "# '/home / User / Documents' \n",
        "os.mkdir(path1) \n",
        "os.mkdir(path2) \n",
        "\n",
        "directory1 = \"left\"\n",
        "directory2 = \"right\"\n",
        "\n",
        "# Parent Directory path \n",
        "parent_dir = \"/content/final_gender_dataset/test\"\n",
        "  \n",
        "# Path \n",
        "path1 = os.path.join(parent_dir, directory1) \n",
        "path2 = os.path.join(parent_dir, directory2) \n",
        "  \n",
        "# Create the directory \n",
        "# 'GeeksForGeeks' in \n",
        "# '/home / User / Documents' \n",
        "os.mkdir(path1) \n",
        "os.mkdir(path2) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXwoAwk_XWBy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "def processImage(img):\n",
        "  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  # res = cv2.resize(gray, dsize=(64, 64), interpolation=cv2.INTER_CUBIC)\n",
        "  # print(res.shape)\n",
        "  return gray"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0nz5biTXXxZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jop9FG3PHC5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "for filename in os.listdir('/content/dataset/Real'):\n",
        "        subject_id, etc = filename.split('__')\n",
        "        gender, lr, finger, _ = etc.split('_')\n",
        "        src='/content/dataset/Real/'+filename\n",
        "        image = cv2.imread(src)\n",
        "\n",
        "        proc_img=(image)\n",
        "\n",
        "        # refer = {\n",
        "        #   \"index\": \"1\",\n",
        "        #   \"middle\": \"2\",\n",
        "        #   \"ring\":\"3\",\n",
        "        #   \"little\":\"4\",\n",
        "        #   \"thumb\":\"5\"\n",
        "        # }\n",
        "\n",
        "        dir_name=''\n",
        "\n",
        "        # if gender=='M':\n",
        "        #   dir_name=dir_name+'male'\n",
        "        # else:\n",
        "        #   dir_name=dir_name+'female'\n",
        "          \n",
        "\n",
        "        if lr=='Left':\n",
        "          dir_name=dir_name+'left'\n",
        "        else:\n",
        "          dir_name=dir_name+'right'\n",
        "\n",
        "        # dir_name=dir_name+refer[finger]\n",
        "\n",
        "        # name=dir_name\n",
        "\n",
        "        # dir_name=name+'_'+str(dic[name])\n",
        "        # final_filename=filename[:-4]+'.png'\n",
        "        cv2.imwrite(os.path.join('/content/final_gender_dataset/training/'+dir_name+'/'+filename),proc_img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PD7KKzGk92NO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import random\n",
        "# Go over each folder path\n",
        "files = os.listdir('/content/final_gender_dataset/training/male')  # Get filenames in current folder\n",
        "\n",
        "files = random.sample(files,3540)  # Pick 900 random files\n",
        "for file in files:\n",
        "  f = os.path.join('/content/final_gender_dataset/training/male', file)  # Create valid path to file\n",
        "  os.remove(f)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxNJSJD_XuiJ",
        "colab_type": "code",
        "outputId": "cdc5cc3f-ffd9-4af9-df87-1a3339093524",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "dir_female_1=os.listdir('/content/final_gender_dataset/training/left')\n",
        "dir_male_1=os.listdir('/content/final_gender_dataset/training/right')\n",
        "dir_female_2=os.listdir('/content/final_gender_dataset/test/left')\n",
        "dir_male_2=os.listdir('/content/final_gender_dataset/test/right')\n",
        "\n",
        "print(len(dir_female_1))\n",
        "print(len(dir_male_1))\n",
        "print(len(dir_female_2))\n",
        "print(len(dir_male_2))\n",
        "\n",
        "\n",
        "findNumImages(dir_female_1)\n",
        "findNumImages(dir_male_1)\n",
        "findNumImages(dir_female_2)\n",
        "findNumImages(dir_male_2)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3000\n",
            "3000\n",
            "0\n",
            "0\n",
            "{'female_left_index': 123, 'female_left_middle': 123, 'female_left_ring': 123, 'female_left_little': 123, 'female_left_thumb': 123, 'female_right_index': 0, 'female_right_middle': 0, 'female_right_ring': 0, 'female_right_little': 0, 'female_right_thumb': 0, 'male_left_index': 477, 'male_left_middle': 477, 'male_left_ring': 477, 'male_left_little': 477, 'male_left_thumb': 477, 'male_right_index': 0, 'male_right_middle': 0, 'male_right_ring': 0, 'male_right_little': 0, 'male_right_thumb': 0}\n",
            "{'female_left_index': 0, 'female_left_middle': 0, 'female_left_ring': 0, 'female_left_little': 0, 'female_left_thumb': 0, 'female_right_index': 123, 'female_right_middle': 123, 'female_right_ring': 123, 'female_right_little': 123, 'female_right_thumb': 123, 'male_left_index': 0, 'male_left_middle': 0, 'male_left_ring': 0, 'male_left_little': 0, 'male_left_thumb': 0, 'male_right_index': 477, 'male_right_middle': 477, 'male_right_ring': 477, 'male_right_little': 477, 'male_right_thumb': 477}\n",
            "{'female_left_index': 0, 'female_left_middle': 0, 'female_left_ring': 0, 'female_left_little': 0, 'female_left_thumb': 0, 'female_right_index': 0, 'female_right_middle': 0, 'female_right_ring': 0, 'female_right_little': 0, 'female_right_thumb': 0, 'male_left_index': 0, 'male_left_middle': 0, 'male_left_ring': 0, 'male_left_little': 0, 'male_left_thumb': 0, 'male_right_index': 0, 'male_right_middle': 0, 'male_right_ring': 0, 'male_right_little': 0, 'male_right_thumb': 0}\n",
            "{'female_left_index': 0, 'female_left_middle': 0, 'female_left_ring': 0, 'female_left_little': 0, 'female_left_thumb': 0, 'female_right_index': 0, 'female_right_middle': 0, 'female_right_ring': 0, 'female_right_little': 0, 'female_right_thumb': 0, 'male_left_index': 0, 'male_left_middle': 0, 'male_left_ring': 0, 'male_left_little': 0, 'male_left_thumb': 0, 'male_right_index': 0, 'male_right_middle': 0, 'male_right_ring': 0, 'male_right_little': 0, 'male_right_thumb': 0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrbpUqVPX_Hr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def findNumImages(files):\n",
        "\n",
        "  diction={\n",
        "      'female_left_index':0,\n",
        "      'female_left_middle':0,\n",
        "      'female_left_ring':0,\n",
        "      'female_left_little':0,\n",
        "      'female_left_thumb':0,\n",
        "      'female_right_index':0,\n",
        "      'female_right_middle':0,\n",
        "      'female_right_ring':0,\n",
        "      'female_right_little':0,\n",
        "      'female_right_thumb':0,\n",
        "      'male_left_index':0,\n",
        "      'male_left_middle':0,\n",
        "      'male_left_ring':0,\n",
        "      'male_left_little':0,\n",
        "      'male_left_thumb':0,\n",
        "      'male_right_index':0,\n",
        "      'male_right_middle':0,\n",
        "      'male_right_ring':0,\n",
        "      'male_right_little':0,\n",
        "      'male_right_thumb':0,\n",
        "      \n",
        "  }\n",
        "  \n",
        "\n",
        "  for filename in files:\n",
        "    subject_id, etc = filename.split('__')\n",
        "    gender, lr, finger, _ = etc.split('_')\n",
        "\n",
        "    name=''\n",
        "\n",
        "    if gender=='M':\n",
        "      name+='male_'\n",
        "    else:\n",
        "      name+='female_'\n",
        "\n",
        "\n",
        "    if lr=='Left':\n",
        "      name=name+'left_'\n",
        "    else:\n",
        "      name=name+'right_'\n",
        "\n",
        "    name+=finger\n",
        "\n",
        "    val=diction[name]\n",
        "\n",
        "    val=val+1\n",
        "\n",
        "    diction[name]=val\n",
        "\n",
        "    \n",
        "  print(diction)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5J6OeKcuVZ-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil\n",
        "import os\n",
        "import numpy as np\n",
        "import argparse\n",
        "\n",
        "def get_files_from_folder(path):\n",
        "\n",
        "    files = os.listdir(path)\n",
        "    return np.asarray(files)\n",
        "\n",
        "def main(path_to_data, path_to_test_data, train_ratio):\n",
        "    # get dirs\n",
        "    _, dirs, _ = next(os.walk(path_to_data))\n",
        "\n",
        "    # calculates how many train data per class\n",
        "    data_counter_per_class = np.zeros((len(dirs)))\n",
        "    for i in range(len(dirs)):\n",
        "        path = os.path.join(path_to_data, dirs[i])\n",
        "        files = get_files_from_folder(path)\n",
        "        data_counter_per_class[i] = len(files)\n",
        "    test_counter = np.round(data_counter_per_class * (1 - train_ratio))\n",
        "\n",
        "    # transfers files\n",
        "    for i in range(len(dirs)):\n",
        "        path_to_original = os.path.join(path_to_data, dirs[i])\n",
        "        path_to_save = os.path.join(path_to_test_data, dirs[i])\n",
        "\n",
        "        #creates dir\n",
        "        if not os.path.exists(path_to_save):\n",
        "            os.makedirs(path_to_save)\n",
        "        files = get_files_from_folder(path_to_original)\n",
        "        # moves data\n",
        "        for j in range(int(test_counter[i])):\n",
        "            dst = os.path.join(path_to_save, files[j])\n",
        "            src = os.path.join(path_to_original, files[j])\n",
        "            shutil.move(src, dst)\n",
        "\n",
        "    \n",
        "# def parse_args():\n",
        "#   parser = argparse.ArgumentParser(description=\"Dataset divider\")\n",
        "#   parser.add_argument(\"--data_path\", required=True,\n",
        "#     help=\"Path to data\")\n",
        "#   parser.add_argument(\"--test_data_path_to_save\", required=True,\n",
        "#     help=\"Path to test data where to save\")\n",
        "#   parser.add_argument(\"--train_ratio\", required=True,\n",
        "#     help=\"Train ratio - 0.7 means splitting data in 70 % train and 30 % test\")\n",
        "#   return parser.parse_args()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  # args = parse_args()\n",
        "  # args.data_path='/content/final_dataset/training'\n",
        "  # args.test_data_path_to_save='/content/final_dataset/test'\n",
        "  # args.train_ratio=0.8\n",
        "  main('/content/final_gender_dataset/training','/content/final_gender_dataset/test', float(0.8))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0E54TFiYDy0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCLcxDZ8jxYc",
        "colab_type": "code",
        "outputId": "4db9a78c-898f-4351-bf4b-5b9aff9853a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "\n",
        "train_datagen=ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True, \n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "test_datagen=ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\n",
        "training_set=train_datagen.flow_from_directory(\n",
        "    '/content/output/train',\n",
        "    target_size=(96,96),\n",
        "    batch_size=8,\n",
        "    class_mode='binary',\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "\n",
        "val_set=test_datagen.flow_from_directory(\n",
        "    '/content/output/val',\n",
        "    target_size=(96,96),\n",
        "    batch_size=8,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "\n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4800 images belonging to 2 classes.\n",
            "Found 600 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSOq_-uanbLV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        " \n",
        "def define_model():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32,(3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(96, 96, 3)))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  opt = optimizers.adam(lr=0.0001)\n",
        "  model.compile(optimizer=opt,loss='binary_crossentropy',metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kb3jzDNFYJA8",
        "colab_type": "code",
        "outputId": "29d37d1b-bee8-492f-8703-3fe2cbdfd6f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "\n",
        "base_model = ResNet50(weights='imagenet', \n",
        "                      include_top=False, \n",
        "                      input_shape=(96, 96, 3))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94658560/94653016 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfBBjzgQmMJ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1pYW6fk_EZs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Dense, Activation, Flatten, Dropout\n",
        "from keras.models import Sequential, Model\n",
        "\n",
        "def build_finetune_model(base_model, dropout, fc_layers, num_classes):\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    x = base_model.output\n",
        "    x = Flatten()(x)\n",
        "    for fc in fc_layers:\n",
        "        # New FC layer, random init\n",
        "        x = Dense(fc, activation='relu')(x) \n",
        "        x = Dropout(dropout)(x)\n",
        "\n",
        "    # New softmax layer\n",
        "    predictions = Dense(num_classes, activation='softmax')(x) \n",
        "    \n",
        "    finetune_model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "    return finetune_model\n",
        "\n",
        "class_list = [\"left\", \"right\"]\n",
        "FC_LAYERS = [1024, 1024]\n",
        "dropout = 0.5\n",
        "\n",
        "finetune_model = build_finetune_model(base_model, \n",
        "                                      dropout=dropout, \n",
        "                                      fc_layers=FC_LAYERS, \n",
        "                                      num_classes=len(class_list))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6k9XEx1_cmY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "opt = optimizers.adam(lr=0.0001)\n",
        "finetune_model.compile(optimizer=opt,loss='binary_crossentropy',metrics=['accuracy'])\n",
        "# finetune_model.compile(loss='categorical_crossentropy',\n",
        "#    optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "#    metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4uPi5-g_wah",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a16edd5a-a7ff-4fcf-838b-04f70d11de4b"
      },
      "source": [
        "from IPython.display import display\n",
        "from PIL import Image\n",
        "\n",
        "mod=define_model()\n",
        "mod.fit_generator(training_set,\n",
        "                    steps_per_epoch=training_set.samples // 8,\n",
        "                    epochs=50,\n",
        "                    validation_data=val_set,\n",
        "                    nb_val_samples= val_set.samples //8)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., steps_per_epoch=600, epochs=50, validation_data=<keras_pre..., validation_steps=75)`\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "600/600 [==============================] - 16s 27ms/step - loss: 0.7928 - acc: 0.6046 - val_loss: 0.8890 - val_acc: 0.5983\n",
            "Epoch 2/50\n",
            "600/600 [==============================] - 15s 26ms/step - loss: 0.6659 - acc: 0.6333 - val_loss: 0.6592 - val_acc: 0.6400\n",
            "Epoch 3/50\n",
            "600/600 [==============================] - 16s 27ms/step - loss: 0.6258 - acc: 0.6575 - val_loss: 0.6509 - val_acc: 0.6700\n",
            "Epoch 4/50\n",
            "600/600 [==============================] - 15s 25ms/step - loss: 0.6072 - acc: 0.6690 - val_loss: 0.7277 - val_acc: 0.6417\n",
            "Epoch 5/50\n",
            "600/600 [==============================] - 15s 25ms/step - loss: 0.6005 - acc: 0.6740 - val_loss: 0.6881 - val_acc: 0.6717\n",
            "Epoch 6/50\n",
            "600/600 [==============================] - 15s 25ms/step - loss: 0.5889 - acc: 0.6785 - val_loss: 0.6590 - val_acc: 0.6683\n",
            "Epoch 7/50\n",
            "600/600 [==============================] - 15s 24ms/step - loss: 0.5814 - acc: 0.6906 - val_loss: 0.7287 - val_acc: 0.6617\n",
            "Epoch 8/50\n",
            "600/600 [==============================] - 15s 24ms/step - loss: 0.5650 - acc: 0.7083 - val_loss: 0.6212 - val_acc: 0.7000\n",
            "Epoch 9/50\n",
            "600/600 [==============================] - 15s 24ms/step - loss: 0.5360 - acc: 0.7292 - val_loss: 0.6421 - val_acc: 0.6950\n",
            "Epoch 10/50\n",
            "600/600 [==============================] - 14s 24ms/step - loss: 0.5098 - acc: 0.7517 - val_loss: 0.6623 - val_acc: 0.7083\n",
            "Epoch 11/50\n",
            "600/600 [==============================] - 14s 24ms/step - loss: 0.4857 - acc: 0.7671 - val_loss: 0.5195 - val_acc: 0.7433\n",
            "Epoch 12/50\n",
            "600/600 [==============================] - 15s 25ms/step - loss: 0.4651 - acc: 0.7788 - val_loss: 0.5338 - val_acc: 0.7633\n",
            "Epoch 13/50\n",
            "600/600 [==============================] - 15s 25ms/step - loss: 0.4489 - acc: 0.7906 - val_loss: 0.4649 - val_acc: 0.7800\n",
            "Epoch 14/50\n",
            "600/600 [==============================] - 15s 24ms/step - loss: 0.4421 - acc: 0.7927 - val_loss: 0.4160 - val_acc: 0.8000\n",
            "Epoch 15/50\n",
            "600/600 [==============================] - 14s 24ms/step - loss: 0.4258 - acc: 0.8065 - val_loss: 0.4935 - val_acc: 0.7883\n",
            "Epoch 16/50\n",
            "600/600 [==============================] - 15s 24ms/step - loss: 0.4153 - acc: 0.8083 - val_loss: 0.4394 - val_acc: 0.8033\n",
            "Epoch 17/50\n",
            "600/600 [==============================] - 14s 24ms/step - loss: 0.4114 - acc: 0.8079 - val_loss: 0.4404 - val_acc: 0.8050\n",
            "Epoch 18/50\n",
            "600/600 [==============================] - 14s 24ms/step - loss: 0.3997 - acc: 0.8167 - val_loss: 0.4248 - val_acc: 0.8133\n",
            "Epoch 19/50\n",
            "600/600 [==============================] - 14s 24ms/step - loss: 0.3980 - acc: 0.8200 - val_loss: 0.4048 - val_acc: 0.8050\n",
            "Epoch 20/50\n",
            "600/600 [==============================] - 14s 24ms/step - loss: 0.3897 - acc: 0.8273 - val_loss: 0.4240 - val_acc: 0.8083\n",
            "Epoch 21/50\n",
            "600/600 [==============================] - 14s 24ms/step - loss: 0.3835 - acc: 0.8279 - val_loss: 0.3965 - val_acc: 0.8283\n",
            "Epoch 22/50\n",
            "600/600 [==============================] - 14s 24ms/step - loss: 0.3870 - acc: 0.8179 - val_loss: 0.3629 - val_acc: 0.8433\n",
            "Epoch 23/50\n",
            "600/600 [==============================] - 14s 24ms/step - loss: 0.3810 - acc: 0.8281 - val_loss: 0.3926 - val_acc: 0.8417\n",
            "Epoch 24/50\n",
            "600/600 [==============================] - 15s 24ms/step - loss: 0.3722 - acc: 0.8287 - val_loss: 0.4417 - val_acc: 0.8217\n",
            "Epoch 25/50\n",
            "600/600 [==============================] - 14s 24ms/step - loss: 0.3666 - acc: 0.8342 - val_loss: 0.3987 - val_acc: 0.8433\n",
            "Epoch 26/50\n",
            "600/600 [==============================] - 14s 24ms/step - loss: 0.3568 - acc: 0.8354 - val_loss: 0.4563 - val_acc: 0.8117\n",
            "Epoch 27/50\n",
            "600/600 [==============================] - 14s 24ms/step - loss: 0.3648 - acc: 0.8342 - val_loss: 0.3812 - val_acc: 0.8400\n",
            "Epoch 28/50\n",
            "600/600 [==============================] - 14s 24ms/step - loss: 0.3557 - acc: 0.8381 - val_loss: 0.3923 - val_acc: 0.8450\n",
            "Epoch 29/50\n",
            "600/600 [==============================] - 15s 24ms/step - loss: 0.3456 - acc: 0.8440 - val_loss: 0.3875 - val_acc: 0.8417\n",
            "Epoch 30/50\n",
            "600/600 [==============================] - 14s 24ms/step - loss: 0.3485 - acc: 0.8450 - val_loss: 0.3657 - val_acc: 0.8483\n",
            "Epoch 31/50\n",
            "600/600 [==============================] - 14s 24ms/step - loss: 0.3431 - acc: 0.8475 - val_loss: 0.3907 - val_acc: 0.8450\n",
            "Epoch 32/50\n",
            "600/600 [==============================] - 15s 25ms/step - loss: 0.3329 - acc: 0.8523 - val_loss: 0.4951 - val_acc: 0.8150\n",
            "Epoch 33/50\n",
            "600/600 [==============================] - 16s 26ms/step - loss: 0.3322 - acc: 0.8527 - val_loss: 0.3671 - val_acc: 0.8433\n",
            "Epoch 34/50\n",
            "600/600 [==============================] - 16s 26ms/step - loss: 0.3346 - acc: 0.8515 - val_loss: 0.3540 - val_acc: 0.8550\n",
            "Epoch 35/50\n",
            "600/600 [==============================] - 15s 26ms/step - loss: 0.3273 - acc: 0.8512 - val_loss: 0.3819 - val_acc: 0.8483\n",
            "Epoch 36/50\n",
            "600/600 [==============================] - 15s 26ms/step - loss: 0.3307 - acc: 0.8556 - val_loss: 0.3568 - val_acc: 0.8467\n",
            "Epoch 37/50\n",
            "600/600 [==============================] - 14s 24ms/step - loss: 0.3201 - acc: 0.8544 - val_loss: 0.3766 - val_acc: 0.8433\n",
            "Epoch 38/50\n",
            "600/600 [==============================] - 15s 26ms/step - loss: 0.3180 - acc: 0.8613 - val_loss: 0.3811 - val_acc: 0.8383\n",
            "Epoch 39/50\n",
            "600/600 [==============================] - 15s 25ms/step - loss: 0.3146 - acc: 0.8642 - val_loss: 0.3424 - val_acc: 0.8600\n",
            "Epoch 40/50\n",
            "600/600 [==============================] - 14s 24ms/step - loss: 0.3039 - acc: 0.8658 - val_loss: 0.3709 - val_acc: 0.8533\n",
            "Epoch 41/50\n",
            "600/600 [==============================] - 14s 24ms/step - loss: 0.3092 - acc: 0.8619 - val_loss: 0.3605 - val_acc: 0.8483\n",
            "Epoch 42/50\n",
            "600/600 [==============================] - 14s 24ms/step - loss: 0.2949 - acc: 0.8723 - val_loss: 0.4053 - val_acc: 0.8367\n",
            "Epoch 43/50\n",
            "600/600 [==============================] - 14s 24ms/step - loss: 0.2999 - acc: 0.8663 - val_loss: 0.5495 - val_acc: 0.8067\n",
            "Epoch 44/50\n",
            "600/600 [==============================] - 14s 24ms/step - loss: 0.3035 - acc: 0.8679 - val_loss: 0.3510 - val_acc: 0.8583\n",
            "Epoch 45/50\n",
            "600/600 [==============================] - 15s 24ms/step - loss: 0.3062 - acc: 0.8665 - val_loss: 0.4534 - val_acc: 0.8150\n",
            "Epoch 46/50\n",
            "600/600 [==============================] - 14s 24ms/step - loss: 0.3026 - acc: 0.8681 - val_loss: 0.3744 - val_acc: 0.8500\n",
            "Epoch 47/50\n",
            "600/600 [==============================] - 14s 24ms/step - loss: 0.3009 - acc: 0.8754 - val_loss: 0.3842 - val_acc: 0.8583\n",
            "Epoch 48/50\n",
            "600/600 [==============================] - 14s 24ms/step - loss: 0.2917 - acc: 0.8717 - val_loss: 0.3862 - val_acc: 0.8667\n",
            "Epoch 49/50\n",
            "600/600 [==============================] - 14s 24ms/step - loss: 0.2896 - acc: 0.8742 - val_loss: 0.3745 - val_acc: 0.8450\n",
            "Epoch 50/50\n",
            "600/600 [==============================] - 14s 24ms/step - loss: 0.2935 - acc: 0.8733 - val_loss: 0.3958 - val_acc: 0.8417\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f010d3d75c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIbfsiOjmNLE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "65fe676b-c9fd-414d-b253-1c321484d138"
      },
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "estimator = KerasClassifier(build_fn=finetune_model, epochs=200, batch_size=5, verbose=0)\n",
        "kfold = KFold(n_splits=10, shuffle=True)\n",
        "results = cross_val_score(estimator, training_set, dummy_y, cv=kfold)\n",
        "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-f816827977a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKerasClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfinetune_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mkfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Baseline: %.2f%% (%.2f%%)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUvoCsc6dB_f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "f0695d3a-9935-48a6-a9c1-0be7334bac23"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "Y_pred = finetune_model.predict_generator(test_set, 738 // 64)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(test_set.classes[:704], y_pred))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-a0f41cc5ec4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinetune_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m738\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Confusion Matrix'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m704\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name '_set' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMl_qXZxdNlA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a6ca09bb-e1d3-4951-bd1e-f4014a3ba491"
      },
      "source": [
        "test_datagen=ImageDataGenerator(rescale=1./255)\n",
        "test_set=train_datagen.flow_from_directory(\n",
        "    '/content/output/test',\n",
        "    target_size=(96,96),\n",
        "    batch_size=8,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "_, acc = mod.evaluate_generator(test_set, steps=len(test_set), verbose=0)\n",
        "print('Test Accuracy: %.3f' % (acc * 100))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 600 images belonging to 2 classes.\n",
            "Test Accuracy: 85.500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAUDZlBjOsOS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCt-f7vqdVwp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b558aabe-d1de-4ed0-8dd3-0d08552d7f3c"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "Y_pred =mod.predict_generator(test_set, 600 //8)\n",
        "# print(Y_pred[:20])\n",
        "\n",
        "for i in range(600):\n",
        "  if Y_pred[i]<=0.5:\n",
        "    Y_pred[i]=0\n",
        "  else:\n",
        "    Y_pred[i]=1\n",
        "\n",
        "# print(Y_pred)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "# print('hi')\n",
        "# print(y_pred[:20])\n",
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(test_set.classes[:600],Y_pred))"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix\n",
            "[[258  42]\n",
            " [ 42 258]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}